\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{none/global//global/global}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Tables and Figures}{1}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{List of Tables}{1}{section*.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{List of Figures}{3}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\nonumberline List of Common Terms and Symbols}{5}{chapter*.6}\protected@file@percent }
\abx@aux@cite{Collobert}
\abx@aux@segm{0}{0}{Collobert}
\abx@aux@cite{Kang2013}
\abx@aux@segm{0}{0}{Kang2013}
\abx@aux@cite{Brill}
\abx@aux@segm{0}{0}{Brill}
\abx@aux@cite{Chiticariu2013}
\abx@aux@segm{0}{0}{Chiticariu2013}
\abx@aux@cite{Kaur2014}
\abx@aux@segm{0}{0}{Kaur2014}
\abx@aux@cite{Nederhof}
\abx@aux@segm{0}{0}{Nederhof}
\abx@aux@cite{Tenney2019a}
\abx@aux@segm{0}{0}{Tenney2019a}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}(A brief) History of NLP}{7}{section.1.1}\protected@file@percent }
\newlabel{section:intro:history}{{1.1}{7}{(A brief) History of NLP}{section.1.1}{}}
\abx@aux@cite{Nilsson}
\abx@aux@segm{0}{0}{Nilsson}
\abx@aux@cite{Harris1954}
\abx@aux@segm{0}{0}{Harris1954}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Potential NLP ``pre-task" pipeline required for a model to solve more complex tasks\relax }}{8}{figure.1.1}\protected@file@percent }
\newlabel{fig:intro:nlppipeline}{{1.1}{8}{Potential NLP ``pre-task" pipeline required for a model to solve more complex tasks\relax }{figure.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.2}Thesis Focus}{8}{section.1.2}\protected@file@percent }
\newlabel{section:intro:projectfocus}{{1.2}{8}{Thesis Focus}{section.1.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Aspect Based Sentiment Analysis}{8}{subsection.1.2.1}\protected@file@percent }
\newlabel{section:intro:absa}{{1.2.1}{8}{Aspect Based Sentiment Analysis}{subsection.1.2.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Example ABSA Knowledge Graph Construction. \newline  Here, \textbf  {[LOG]} = ``The restaurant was really cheap, but it didnt have a great vibe". \newline  An alternative presentation of the above is that the aspect nodes have sentiment attributes, rather than an additional relation to a seperate node in the graph.\relax }}{9}{figure.1.2}\protected@file@percent }
\newlabel{fig:intro:absa}{{1.2}{9}{Example ABSA Knowledge Graph Construction. \newline Here, \textbf {[LOG]} = ``The restaurant was really cheap, but it didnt have a great vibe". \newline An alternative presentation of the above is that the aspect nodes have sentiment attributes, rather than an additional relation to a seperate node in the graph.\relax }{figure.1.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Transfer Learning}{9}{subsection.1.2.2}\protected@file@percent }
\newlabel{section:intro:intrototransfer}{{1.2.2}{9}{Transfer Learning}{subsection.1.2.2}{}}
\abx@aux@cite{Caruana1997}
\abx@aux@segm{0}{0}{Caruana1997}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Multitask Learning}{10}{subsection.1.2.3}\protected@file@percent }
\newlabel{section:intro:introtomultitask}{{1.2.3}{10}{Multitask Learning}{subsection.1.2.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Meta Learning}{10}{subsection.1.2.4}\protected@file@percent }
\newlabel{section:intro:introtometa}{{1.2.4}{10}{Meta Learning}{subsection.1.2.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.3}Project Aims \& Our Contributions}{11}{section.1.3}\protected@file@percent }
\newlabel{section:intro:projectaims}{{1.3}{11}{Project Aims \& Our Contributions}{section.1.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.4}Commercial Applications}{12}{section.1.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.5}Public Code Repository}{12}{section.1.5}\protected@file@percent }
\newlabel{section:intro:code}{{1.5}{12}{Public Code Repository}{section.1.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{13}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:background}{{2}{13}{Background}{chapter.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}The Evolution of Language Modelling}{13}{section.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Problem Setup}{13}{subsection.2.1.1}\protected@file@percent }
\newlabel{section:background:problemsetup}{{2.1.1}{13}{Problem Setup}{subsection.2.1.1}{}}
\abx@aux@cite{Brown}
\abx@aux@segm{0}{0}{Brown}
\abx@aux@cite{Mikolov}
\abx@aux@segm{0}{0}{Mikolov}
\abx@aux@cite{Mikolov2013}
\abx@aux@segm{0}{0}{Mikolov2013}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}$n-$gram models}{14}{subsection.2.1.2}\protected@file@percent }
\newlabel{section:background:ngram}{{2.1.2}{14}{$n-$gram models}{subsection.2.1.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Pretrained Word Embeddings: Humble Beginnings}{14}{subsection.2.1.3}\protected@file@percent }
\newlabel{section:background:wordembeddings}{{2.1.3}{14}{Pretrained Word Embeddings: Humble Beginnings}{subsection.2.1.3}{}}
\abx@aux@cite{Pennington}
\abx@aux@segm{0}{0}{Pennington}
\abx@aux@segm{0}{0}{Mikolov}
\abx@aux@segm{0}{0}{Pennington}
\abx@aux@cite{VanDerMaaten2008}
\abx@aux@segm{0}{0}{VanDerMaaten2008}
\abx@aux@cite{Kullback1951}
\abx@aux@segm{0}{0}{Kullback1951}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Continuous Bag Of Word (CBOW) models vs Skip Gram Models \newline  Skip Gram models predict a words context given the word itself, whereas CBOW models predict a word given its context.\relax }}{15}{figure.2.1}\protected@file@percent }
\newlabel{fig:background:SkipGramvsCBOW}{{2.1}{15}{Continuous Bag Of Word (CBOW) models vs Skip Gram Models \newline Skip Gram models predict a words context given the word itself, whereas CBOW models predict a word given its context.\relax }{figure.2.1}{}}
\abx@aux@segm{0}{0}{Mikolov}
\abx@aux@segm{0}{0}{Mikolov}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The reduced dimensionality word embedding space found using \texttt  {word2vec} \cite {Mikolov} and the algebraic relationship between clusters of words in this space\relax }}{16}{figure.2.2}\protected@file@percent }
\newlabel{fig:background:wordembeddings}{{2.2}{16}{The reduced dimensionality word embedding space found using \texttt {word2vec} \cite {Mikolov} and the algebraic relationship between clusters of words in this space\relax }{figure.2.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}The Rise of Deep Learning: Using Sequentiality for Context}{16}{subsection.2.1.4}\protected@file@percent }
\newlabel{section:background:bidirectional}{{2.1.4}{16}{The Rise of Deep Learning: Using Sequentiality for Context}{subsection.2.1.4}{}}
\abx@aux@cite{Elman1990}
\abx@aux@segm{0}{0}{Elman1990}
\abx@aux@cite{Werbos}
\abx@aux@segm{0}{0}{Werbos}
\abx@aux@cite{Pascanu}
\abx@aux@segm{0}{0}{Pascanu}
\abx@aux@cite{Hochreiter1997}
\abx@aux@segm{0}{0}{Hochreiter1997}
\abx@aux@cite{Varsamopoulos2018}
\abx@aux@segm{0}{0}{Varsamopoulos2018}
\abx@aux@segm{0}{0}{Varsamopoulos2018}
\abx@aux@cite{Graves2013}
\abx@aux@segm{0}{0}{Graves2013}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Recurrent Neural Networks}{17}{section*.7}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces One LSTM cell with corresponding equations, image taken from \cite {Varsamopoulos2018}. There is one cell for each word in the input sentence. We input embedding $x_t$, and propagate forward the hidden state $h_t$ and the cell state $C_t$. $\{i_t, f_t, o_t\}$ are the \{input, forget, output\} gates, $W^{\{i,f,o\}}$ and $U^{\{i,f,o\}}$ are learnable weight matrices.\relax }}{17}{figure.2.3}\protected@file@percent }
\newlabel{fig:background:lstm}{{2.3}{17}{One LSTM cell with corresponding equations, image taken from \cite {Varsamopoulos2018}. There is one cell for each word in the input sentence. We input embedding $x_t$, and propagate forward the hidden state $h_t$ and the cell state $C_t$. $\{i_t, f_t, o_t\}$ are the \{input, forget, output\} gates, $W^{\{i,f,o\}}$ and $U^{\{i,f,o\}}$ are learnable weight matrices.\relax }{figure.2.3}{}}
\abx@aux@segm{0}{0}{Graves2013}
\abx@aux@segm{0}{0}{Graves2013}
\abx@aux@cite{Peters2018a}
\abx@aux@segm{0}{0}{Peters2018a}
\abx@aux@segm{0}{0}{Peters2018a}
\abx@aux@cite{RadfordGPT}
\abx@aux@segm{0}{0}{RadfordGPT}
\abx@aux@cite{Vaswani}
\abx@aux@segm{0}{0}{Vaswani}
\abx@aux@cite{Dai2019}
\abx@aux@segm{0}{0}{Dai2019}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Bidirectional LSTM architecture as defined in \cite {Graves2013}\relax }}{18}{figure.2.4}\protected@file@percent }
\newlabel{fig:background:bidirectionallstm}{{2.4}{18}{Bidirectional LSTM architecture as defined in \cite {Graves2013}\relax }{figure.2.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{ELMo \& GPT}{18}{section*.12}\protected@file@percent }
\abx@aux@cite{He2015}
\abx@aux@segm{0}{0}{He2015}
\abx@aux@cite{Huang2016}
\abx@aux@segm{0}{0}{Huang2016}
\abx@aux@cite{ImageNet}
\abx@aux@segm{0}{0}{ImageNet}
\abx@aux@cite{COCO}
\abx@aux@segm{0}{0}{COCO}
\abx@aux@cite{Howard2018}
\abx@aux@segm{0}{0}{Howard2018}
\abx@aux@cite{RuderThesis}
\abx@aux@segm{0}{0}{RuderThesis}
\abx@aux@segm{0}{0}{Vaswani}
\abx@aux@cite{Cheng2016}
\abx@aux@segm{0}{0}{Cheng2016}
\abx@aux@cite{Parikh}
\abx@aux@segm{0}{0}{Parikh}
\abx@aux@cite{Paulus2017}
\abx@aux@segm{0}{0}{Paulus2017}
\abx@aux@cite{Lin2017}
\abx@aux@segm{0}{0}{Lin2017}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Current SOTA Language Modelling: Transformers}{19}{section.2.2}\protected@file@percent }
\newlabel{section:background:LMs}{{2.2}{19}{Current SOTA Language Modelling: Transformers}{section.2.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Transformer Architecture}{19}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Attention: An Introduction}{19}{section*.13}\protected@file@percent }
\abx@aux@segm{0}{0}{He2015}
\abx@aux@cite{Ba2016}
\abx@aux@segm{0}{0}{Ba2016}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Encoder and Decoder Architecture}{20}{section*.14}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Attention: The Mathematical Formalism}{20}{section*.15}\protected@file@percent }
\abx@aux@segm{0}{0}{Vaswani}
\abx@aux@segm{0}{0}{Vaswani}
\abx@aux@segm{0}{0}{Vaswani}
\abx@aux@cite{Jain}
\abx@aux@segm{0}{0}{Jain}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces The Architecture of the Transformer Model \cite {Vaswani}\relax }}{21}{figure.2.5}\protected@file@percent }
\newlabel{fig:background:transformer}{{2.5}{21}{The Architecture of the Transformer Model \cite {Vaswani}\relax }{figure.2.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Benefits of Self Attention}{21}{section*.16}\protected@file@percent }
\abx@aux@cite{Devlin2018}
\abx@aux@segm{0}{0}{Devlin2018}
\abx@aux@cite{Wang2018}
\abx@aux@segm{0}{0}{Wang2018}
\abx@aux@cite{Taylor1953}
\abx@aux@segm{0}{0}{Taylor1953}
\abx@aux@cite{Liu2019}
\abx@aux@segm{0}{0}{Liu2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}BERT}{22}{subsection.2.2.2}\protected@file@percent }
\newlabel{section:background:bert}{{2.2.2}{22}{BERT}{subsection.2.2.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces BERT vs OpenAI GPT vs ELMo\relax }}{22}{figure.2.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Masked Language Modelling - Cloze Task}{22}{section*.17}\protected@file@percent }
\abx@aux@cite{Wu2016}
\abx@aux@segm{0}{0}{Wu2016}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{WordPiece Tokenisation}{23}{section*.18}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Next Sentence Prediction Pretraining task}{23}{section*.19}\protected@file@percent }
\abx@aux@segm{0}{0}{Vaswani}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Token Structure}{24}{section*.20}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces BERT Token Prediction\relax }}{24}{figure.2.7}\protected@file@percent }
\newlabel{fig:background:berttokenprediction}{{2.7}{24}{BERT Token Prediction\relax }{figure.2.7}{}}
\abx@aux@segm{0}{0}{Vaswani}
\abx@aux@segm{0}{0}{Vaswani}
\abx@aux@segm{0}{0}{Devlin2018}
\abx@aux@segm{0}{0}{Liu2019}
\abx@aux@cite{Yang2019}
\abx@aux@segm{0}{0}{Yang2019}
\abx@aux@cite{XLNetTeam2019}
\abx@aux@segm{0}{0}{XLNetTeam2019}
\abx@aux@segm{0}{0}{XLNetTeam2019}
\abx@aux@cite{Tenney2019}
\abx@aux@segm{0}{0}{Tenney2019}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces BERT Embeddings. In addition to the learned token embeddings, there are segment embeddings (as to whether or not we are in the first sentence or second sentence) and positional embeddings \cite {Vaswani} that help indicate the relative positioning of tokens in the sentence.\relax }}{25}{figure.2.8}\protected@file@percent }
\newlabel{fig:background:bertembeddings}{{2.8}{25}{BERT Embeddings. In addition to the learned token embeddings, there are segment embeddings (as to whether or not we are in the first sentence or second sentence) and positional embeddings \cite {Vaswani} that help indicate the relative positioning of tokens in the sentence.\relax }{figure.2.8}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Ablation Study}{25}{section*.21}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Recreating the NLP Pipeline}{25}{section*.22}\protected@file@percent }
\abx@aux@segm{0}{0}{Tenney2019}
\abx@aux@segm{0}{0}{Tenney2019}
\abx@aux@segm{0}{0}{Dai2019}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces BERT correcting its predictions along the model depth layers, taken from \cite {Tenney2019}\relax }}{26}{figure.2.9}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}XLNet}{26}{subsection.2.2.3}\protected@file@percent }
\newlabel{section:background:xlnet}{{2.2.3}{26}{XLNet}{subsection.2.2.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Autoregressive vs Autoencoding Language Modelling: BERT vs XLNet}{26}{section*.23}\protected@file@percent }
\abx@aux@segm{0}{0}{Devlin2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Permutation Language Modelling - An alternative pretraining objective}{27}{section*.24}\protected@file@percent }
\abx@aux@segm{0}{0}{Liu2019}
\abx@aux@segm{0}{0}{XLNetTeam2019}
\abx@aux@segm{0}{0}{Liu2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Ablation Study}{28}{section*.25}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Comparisons with BERT}{28}{section*.26}\protected@file@percent }
\abx@aux@segm{0}{0}{Wang2018}
\abx@aux@cite{Radford2017}
\abx@aux@segm{0}{0}{Radford2017}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Casing in Language Models}{29}{subsection.2.2.4}\protected@file@percent }
\newlabel{section:background:casing}{{2.2.4}{29}{Casing in Language Models}{subsection.2.2.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Sentiment Analysis}{29}{section.2.3}\protected@file@percent }
\abx@aux@cite{Socher}
\abx@aux@segm{0}{0}{Socher}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}SST-2}{30}{subsection.2.3.1}\protected@file@percent }
\newlabel{section:background:sst2}{{2.3.1}{30}{SST-2}{subsection.2.3.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}SemEval 2014 - ABSA}{30}{subsection.2.3.2}\protected@file@percent }
\newlabel{section:background:semeval}{{2.3.2}{30}{SemEval 2014 - ABSA}{subsection.2.3.2}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Subtasks and variants of ABSA. Typically, the polarity categories are \{\texttt  {positive, negative, neutral, conflict}\} where conflict denotes both positive and negative sentiment being expressed simultaneously\relax }}{30}{table.2.1}\protected@file@percent }
\newlabel{table:background:absasubtasks}{{2.1}{30}{Subtasks and variants of ABSA. Typically, the polarity categories are \{\texttt {positive, negative, neutral, conflict}\} where conflict denotes both positive and negative sentiment being expressed simultaneously\relax }{table.2.1}{}}
\abx@aux@cite{Kiritchenko2014}
\abx@aux@segm{0}{0}{Kiritchenko2014}
\abx@aux@cite{Sun2019}
\abx@aux@segm{0}{0}{Sun2019}
\abx@aux@segm{0}{0}{Sun2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Sentihood - TABSA}{31}{subsection.2.3.3}\protected@file@percent }
\newlabel{section:background:sentihood}{{2.3.3}{31}{Sentihood - TABSA}{subsection.2.3.3}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces TABSA Example: {\color  {black} LOCATION2} is in central London, and thus extremely expensive, whilst {\color  {black} LOCATION1} is often considered the coolest area of London.\relax }}{31}{table.2.2}\protected@file@percent }
\newlabel{table:background:tabsaexample}{{2.2}{31}{TABSA Example: {\color {black} LOCATION2} is in central London, and thus extremely expensive, whilst {\color {black} LOCATION1} is often considered the coolest area of London.\relax }{table.2.2}{}}
\abx@aux@segm{0}{0}{Devlin2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}(T)ABSA and LMs: Auxilliary Sentence Construction Method}{32}{subsection.2.3.4}\protected@file@percent }
\newlabel{section:background:tabsasentenceconstruction}{{2.3.4}{32}{(T)ABSA and LMs: Auxilliary Sentence Construction Method}{subsection.2.3.4}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces \textbf  {B}inary Auxilliary Sentence Construction Method for example in Table \ref  {table:background:tabsaexample}\relax }}{32}{table.2.3}\protected@file@percent }
\newlabel{table:background:tabsasentencesB}{{2.3}{32}{\textbf {B}inary Auxilliary Sentence Construction Method for example in Table \ref {table:background:tabsaexample}\relax }{table.2.3}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces \textbf  {M}ultickass Auxilliary Sentence Construction Method for example in Table \ref  {table:background:tabsaexample}\relax }}{32}{table.2.4}\protected@file@percent }
\newlabel{table:background:tabsasentencesM}{{2.4}{32}{\textbf {M}ultickass Auxilliary Sentence Construction Method for example in Table \ref {table:background:tabsaexample}\relax }{table.2.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Analysis of the TABSA Explosion Method}{33}{subsection.2.3.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Multitask learning}{33}{section.2.4}\protected@file@percent }
\newlabel{section:background:multitask}{{2.4}{33}{Multitask learning}{section.2.4}{}}
\abx@aux@cite{Parisi2018}
\abx@aux@segm{0}{0}{Parisi2018}
\abx@aux@segm{0}{0}{RuderThesis}
\abx@aux@cite{Ruder2017}
\abx@aux@segm{0}{0}{Ruder2017}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Transfer Learning Illustration\relax }}{34}{figure.2.10}\protected@file@percent }
\newlabel{fig:background:transferlearning}{{2.10}{34}{Transfer Learning Illustration\relax }{figure.2.10}{}}
\abx@aux@segm{0}{0}{Ruder2017}
\abx@aux@cite{Baxter1997}
\abx@aux@segm{0}{0}{Baxter1997}
\abx@aux@segm{0}{0}{Ruder2017}
\abx@aux@segm{0}{0}{Ruder2017}
\abx@aux@cite{Stickland2019}
\abx@aux@segm{0}{0}{Stickland2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Types of Multitask Learning}{35}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Hard Parameter Sharing}{35}{section*.27}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Hard Parameter Sharing, with image taken from \cite {Ruder2017}\relax }}{35}{figure.2.11}\protected@file@percent }
\newlabel{fig:background:hardparametersharing}{{2.11}{35}{Hard Parameter Sharing, with image taken from \cite {Ruder2017}\relax }{figure.2.11}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Soft Parameter Sharing}{35}{section*.28}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Soft Parameter Sharing, with image taken from \cite {Ruder2017}\relax }}{35}{figure.2.12}\protected@file@percent }
\newlabel{fig:background:softparametersharing}{{2.12}{35}{Soft Parameter Sharing, with image taken from \cite {Ruder2017}\relax }{figure.2.12}{}}
\abx@aux@segm{0}{0}{Wang2018}
\abx@aux@cite{Sanh2018}
\abx@aux@segm{0}{0}{Sanh2018}
\abx@aux@segm{0}{0}{Stickland2019}
\abx@aux@segm{0}{0}{Wang2018}
\abx@aux@segm{0}{0}{Yang2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Adaption Modules}{36}{section*.29}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Sampling Tasks}{36}{subsection.2.4.2}\protected@file@percent }
\newlabel{section:background:samplingtasks}{{2.4.2}{36}{Sampling Tasks}{subsection.2.4.2}{}}
\abx@aux@cite{Sun2019a}
\abx@aux@segm{0}{0}{Sun2019a}
\abx@aux@segm{0}{0}{Devlin2018}
\abx@aux@segm{0}{0}{Yang2019}
\abx@aux@segm{0}{0}{Sun2019a}
\abx@aux@segm{0}{0}{Sun2019a}
\abx@aux@segm{0}{0}{Sun2019a}
\abx@aux@segm{0}{0}{Devlin2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Multitask learning applied to language modelling}{37}{subsection.2.4.3}\protected@file@percent }
\newlabel{section:background:multitasklearningforLMs}{{2.4.3}{37}{Multitask learning applied to language modelling}{subsection.2.4.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{ERNIE 2.0}{37}{section*.30}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces ERNIE 2.0 Methodology \cite {Sun2019a}\relax }}{37}{figure.2.13}\protected@file@percent }
\newlabel{fig:background:ernie}{{2.13}{37}{ERNIE 2.0 Methodology \cite {Sun2019a}\relax }{figure.2.13}{}}
\abx@aux@segm{0}{0}{Sun2019a}
\abx@aux@segm{0}{0}{Sun2019a}
\abx@aux@cite{Garland2019}
\abx@aux@segm{0}{0}{Garland2019}
\abx@aux@cite{Cai2017}
\abx@aux@segm{0}{0}{Cai2017}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces ERNIE 2.0 Pretraining Task Framework \cite {Sun2019a}\relax }}{38}{figure.2.14}\protected@file@percent }
\newlabel{fig:background:ernietaskstructure}{{2.14}{38}{ERNIE 2.0 Pretraining Task Framework \cite {Sun2019a}\relax }{figure.2.14}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Multitask learning applied to ABSA}{38}{subsection.2.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}Multitask learning for Knowledge Graph Construction}{38}{subsection.2.4.5}\protected@file@percent }
\abx@aux@cite{Finn2017}
\abx@aux@segm{0}{0}{Finn2017}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.5}Meta Learning}{39}{section.2.5}\protected@file@percent }
\newlabel{section:background:meta}{{2.5}{39}{Meta Learning}{section.2.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}How we learn to learn}{39}{subsection.2.5.1}\protected@file@percent }
\abx@aux@segm{0}{0}{Finn2017}
\abx@aux@segm{0}{0}{Finn2017}
\abx@aux@segm{0}{0}{Finn2017}
\abx@aux@cite{Nichol}
\abx@aux@segm{0}{0}{Nichol}
\abx@aux@segm{0}{0}{Nichol}
\abx@aux@segm{0}{0}{Nichol}
\abx@aux@segm{0}{0}{Nichol}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}MAML}{40}{subsection.2.5.2}\protected@file@percent }
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Model Agnostic Meta Learning (MAML) \cite {Finn2017}\relax }}{40}{algorithm.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:background:maml}{{1}{40}{Model Agnostic Meta Learning (MAML) \cite {Finn2017}\relax }{algorithm.1}{}}
\abx@aux@cite{Wolf}
\abx@aux@segm{0}{0}{Wolf}
\abx@aux@cite{Chen2018}
\abx@aux@segm{0}{0}{Chen2018}
\abx@aux@segm{0}{0}{Finn2017}
\abx@aux@cite{Gu}
\abx@aux@segm{0}{0}{Gu}
\abx@aux@cite{Yu}
\abx@aux@segm{0}{0}{Yu}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Reptile \& FOMAML}{41}{subsection.2.5.3}\protected@file@percent }
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Reptile \cite {Nichol}\relax }}{41}{algorithm.2}\protected@file@percent }
\newlabel{alg:background:reptile}{{2}{41}{Reptile \cite {Nichol}\relax }{algorithm.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Meta Learning applied to Language Modelling}{41}{subsection.2.5.4}\protected@file@percent }
\abx@aux@segm{0}{0}{Kiritchenko2014}
\abx@aux@segm{0}{0}{Sun2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{42}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:methodology}{{3}{42}{Methodology}{chapter.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Hypothesis}{42}{section.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Task Setup}{42}{section.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Task Structure}{42}{subsection.3.2.1}\protected@file@percent }
\newlabel{section:methodology:taskstructure}{{3.2.1}{42}{Task Structure}{subsection.3.2.1}{}}
\abx@aux@segm{0}{0}{Sun2019}
\abx@aux@segm{0}{0}{Sun2019}
\abx@aux@segm{0}{0}{Sun2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Datasets}{43}{subsection.3.2.2}\protected@file@percent }
\newlabel{section:methodology:datasets}{{3.2.2}{43}{Datasets}{subsection.3.2.2}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Datasets used throughout this thesis, including various properties of each dataset. $^*$ denotes dataset only used for preliminary testing (cf. Section \ref  {section:experiments:sentimentonly}) \newline  $^\dagger $ denotes using the QA\_\textbf  {B} method to create the exploded dataset as described in Table \ref  {table:background:tabsasentencesB}. All sizes are given prior to the explosion of the dataset i.e the raw number of input text sentences for each dataset. In some cases, the dev set is equal to the test set, to match the reporting statistics given in various papers and since we are fixing hyperparameters as per \cite {Sun2019} so no hyperparameter tuning is required\relax }}{43}{table.3.1}\protected@file@percent }
\newlabel{table:methodology:datasets}{{3.1}{43}{Datasets used throughout this thesis, including various properties of each dataset. $^*$ denotes dataset only used for preliminary testing (cf. Section \ref {section:experiments:sentimentonly}) \newline $^\dagger $ denotes using the QA\_\textbf {B} method to create the exploded dataset as described in Table \ref {table:background:tabsasentencesB}. All sizes are given prior to the explosion of the dataset i.e the raw number of input text sentences for each dataset. In some cases, the dev set is equal to the test set, to match the reporting statistics given in various papers and since we are fixing hyperparameters as per \cite {Sun2019} so no hyperparameter tuning is required\relax }{table.3.1}{}}
\abx@aux@segm{0}{0}{Wang2018}
\abx@aux@cite{Tjong}
\abx@aux@segm{0}{0}{Tjong}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{(T)ABSA Data}{44}{section*.31}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{SST-2}{44}{section*.32}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{PoS}{44}{section*.33}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces An example of the tagging schemas for CoNLL 2003\relax }}{44}{table.3.2}\protected@file@percent }
\newlabel{table:methodology:nerexample}{{3.2}{44}{An example of the tagging schemas for CoNLL 2003\relax }{table.3.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Streetbees Data}{44}{section*.34}\protected@file@percent }
\newlabel{section:data:streetbees}{{3.2.2}{44}{Streetbees Data}{section*.34}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Countplot of the Streetbees Data (emotion) categories\relax }}{45}{figure.3.1}\protected@file@percent }
\newlabel{fig:methodology:streetbeesdatahist}{{3.1}{45}{Countplot of the Streetbees Data (emotion) categories\relax }{figure.3.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Task Distributions}{45}{subsection.3.2.3}\protected@file@percent }
\newlabel{section:methodology:taskdistributions}{{3.2.3}{45}{Task Distributions}{subsection.3.2.3}{}}
\newlabel{def:methodology:samplingdistributions}{{3.2.1}{45}{Sampling Distributions}{definition.3.2.1}{}}
\newlabel{def:methodology:taskweightings}{{3.2.2}{45}{Task Weighting}{definition.3.2.2}{}}
\abx@aux@segm{0}{0}{Devlin2018}
\abx@aux@segm{0}{0}{Yang2019}
\newlabel{def:methodology:taskdistributions}{{3.2.3}{46}{Task Distribution}{definition.3.2.3}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces The task weightings corresponding to each importance level\relax }}{46}{table.3.3}\protected@file@percent }
\newlabel{table:methodology:taskweights}{{3.3}{46}{The task weightings corresponding to each importance level\relax }{table.3.3}{}}
\abx@aux@cite{tensorboard}
\abx@aux@segm{0}{0}{tensorboard}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Model Architecture Setup}{47}{section.3.3}\protected@file@percent }
\newlabel{section:methodology:modelsetup}{{3.3}{47}{Model Architecture Setup}{section.3.3}{}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Training Loop Pseudocode\relax }}{48}{algorithm.3}\protected@file@percent }
\newlabel{alg:methodology:training}{{3}{48}{Training Loop Pseudocode\relax }{algorithm.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Reporting}{48}{section.3.4}\protected@file@percent }
\newlabel{section:methodology:reporting}{{3.4}{48}{Reporting}{section.3.4}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces A table showing all the key metrics we will be reporting as per the literature, as well as brief description of each one and the current SOTA. \newline  $^\dagger $ We may refer to these tasks without the prepending ``\_QA\_B" in the thesis with the agreement there is no ambiguity among the tasks described in Section \ref  {section:background:tabsasentenceconstruction} \newline  $^\ddagger $ This metric combines the True Positive Rate (TPR) and the False Positive Rate (FPR) as plotted in the Reciever Operator Curve (ROC) into a singular metric, with 1.0 being perfection and 0.5 being roughly equivalent to random guessing. It is frequent to have ROC scores of greater than 0.95 in SOTA applications.\relax }}{48}{table.3.4}\protected@file@percent }
\newlabel{table:methodology:reporting}{{3.4}{48}{A table showing all the key metrics we will be reporting as per the literature, as well as brief description of each one and the current SOTA. \newline $^\dagger $ We may refer to these tasks without the prepending ``\_QA\_B" in the thesis with the agreement there is no ambiguity among the tasks described in Section \ref {section:background:tabsasentenceconstruction} \newline $^\ddagger $ This metric combines the True Positive Rate (TPR) and the False Positive Rate (FPR) as plotted in the Reciever Operator Curve (ROC) into a singular metric, with 1.0 being perfection and 0.5 being roughly equivalent to random guessing. It is frequent to have ROC scores of greater than 0.95 in SOTA applications.\relax }{table.3.4}{}}
\abx@aux@segm{0}{0}{Sun2019}
\abx@aux@segm{0}{0}{Devlin2018}
\abx@aux@segm{0}{0}{Yang2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiments \& Results}{49}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:experiments}{{4}{49}{Experiments \& Results}{chapter.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Base Language Model Choices}{49}{section.4.1}\protected@file@percent }
\newlabel{section:experiments:languagemodels}{{4.1}{49}{Base Language Model Choices}{section.4.1}{}}
\abx@aux@segm{0}{0}{Sun2019}
\abx@aux@segm{0}{0}{Yang2019}
\abx@aux@segm{0}{0}{Devlin2018}
\abx@aux@segm{0}{0}{Sun2019a}
\abx@aux@segm{0}{0}{Yang2019}
\abx@aux@segm{0}{0}{Liu2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}SemEval (ABSA) Results}{50}{section.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}NLI Pretraining Task Importance}{50}{subsection.4.2.1}\protected@file@percent }
\newlabel{section:experiments:nlipretrainingimportance}{{4.2.1}{50}{NLI Pretraining Task Importance}{subsection.4.2.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces SemEval \{2,3,4\}-way accuracies on BERT and XLNet for our sampling modes\relax }}{51}{figure.caption.35}\protected@file@percent }
\newlabel{fig:experiments:semevalaccs}{{4.1}{51}{SemEval \{2,3,4\}-way accuracies on BERT and XLNet for our sampling modes\relax }{figure.caption.35}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces SemEval \{2,3,4\}-way accuracies relative to SOTA performance on BERT and XLNet for our sampling modes\relax }}{52}{figure.caption.36}\protected@file@percent }
\newlabel{fig:experiments:semevalaccsrelative}{{4.2}{52}{SemEval \{2,3,4\}-way accuracies relative to SOTA performance on BERT and XLNet for our sampling modes\relax }{figure.caption.36}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces SemEval Precision, Recall and $F_1$ Scores on BERT and XLNet for our sampling modes\relax }}{53}{figure.caption.37}\protected@file@percent }
\newlabel{fig:experiments:semevalprf}{{4.3}{53}{SemEval Precision, Recall and $F_1$ Scores on BERT and XLNet for our sampling modes\relax }{figure.caption.37}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Analysis of Results}{54}{subsection.4.2.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces SemEval\_QA\_B 2 way (binary) accuracy results (restricted to the top 5 of each model that beat SOTA performance)\relax }}{55}{table.4.1}\protected@file@percent }
\newlabel{table:experiments:semevalresults}{{4.1}{55}{SemEval\_QA\_B 2 way (binary) accuracy results (restricted to the top 5 of each model that beat SOTA performance)\relax }{table.4.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}An Overview of SOTA Results Achieved}{55}{section.4.3}\protected@file@percent }
\newlabel{section:experiments:allsotaresults}{{4.3}{55}{An Overview of SOTA Results Achieved}{section.4.3}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces SOTA results for the TABSA tasks: SemEval and Sentihood\relax }}{55}{table.4.2}\protected@file@percent }
\newlabel{table:experiments:sotaresults}{{4.2}{55}{SOTA results for the TABSA tasks: SemEval and Sentihood\relax }{table.4.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Streetbees Results}{55}{section.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Multilabel Emotion Results}{56}{subsection.4.4.1}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Streetbees Results, showing the best performing model by $F_1$ Score compared to the baseline fine tuning models\relax }}{56}{table.4.3}\protected@file@percent }
\newlabel{table:experiments:streetbeesresults}{{4.3}{56}{Streetbees Results, showing the best performing model by $F_1$ Score compared to the baseline fine tuning models\relax }{table.4.3}{}}
\abx@aux@segm{0}{0}{Devlin2018}
\abx@aux@segm{0}{0}{Yang2019}
\abx@aux@segm{0}{0}{Sun2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Generalisation Capabilities}{57}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.5}Preliminary Experiments}{57}{section.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Ensuring Baseline Performance}{57}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Gradual Unfreezing of Base Language Model Layers}{58}{subsection.4.5.2}\protected@file@percent }
\newlabel{section:experiments:unfreezing}{{4.5.2}{58}{Gradual Unfreezing of Base Language Model Layers}{subsection.4.5.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Multitask learning for Sentiment Classification}{58}{subsection.4.5.3}\protected@file@percent }
\newlabel{section:experiments:sentimentonly}{{4.5.3}{58}{Multitask learning for Sentiment Classification}{subsection.4.5.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces SST-2 vs IMDB in the single task and multitask learning setting\relax }}{59}{figure.4.4}\protected@file@percent }
\newlabel{fig:experiments:sentimentmultitaskresults}{{4.4}{59}{SST-2 vs IMDB in the single task and multitask learning setting\relax }{figure.4.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.6}Success of the Sampling Schemas}{59}{section.4.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.7}Remark on Task Distributions for Experimental Optimisation}{60}{section.4.7}\protected@file@percent }
\newlabel{section:experiments:taskdistributions}{{4.7}{60}{Remark on Task Distributions for Experimental Optimisation}{section.4.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Observation 1: The Single Task Setting}{60}{section*.38}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Observation 2: The Two Task Setting}{60}{section*.39}\protected@file@percent }
\abx@aux@segm{0}{0}{Sun2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.8}Training Choices}{61}{section.4.8}\protected@file@percent }
\newlabel{section:experiments:training}{{4.8}{61}{Training Choices}{section.4.8}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}Hyperparameters}{61}{subsection.4.8.1}\protected@file@percent }
\newlabel{section:experiments:hyperparameters}{{4.8.1}{61}{Hyperparameters}{subsection.4.8.1}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces The core hyperparameter default values we used throughout our testing\relax }}{61}{table.4.4}\protected@file@percent }
\newlabel{table:experiments:hyperparameters}{{4.4}{61}{The core hyperparameter default values we used throughout our testing\relax }{table.4.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.2}Computing Resources}{61}{subsection.4.8.2}\protected@file@percent }
\newlabel{section:experiments:compute}{{4.8.2}{61}{Computing Resources}{subsection.4.8.2}{}}
\abx@aux@segm{0}{0}{Sun2019}
\abx@aux@segm{0}{0}{Devlin2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Extensions}{62}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:extensions}{{5}{62}{Extensions}{chapter.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}Methodological Refinements}{62}{section.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Training Time}{62}{subsection.5.1.1}\protected@file@percent }
\newlabel{section:extensions:numstepsperepoch}{{5.1.1}{62}{Training Time}{subsection.5.1.1}{}}
\abx@aux@cite{Kuleshov2000}
\abx@aux@segm{0}{0}{Kuleshov2000}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Subtasks}{63}{subsection.5.1.2}\protected@file@percent }
\newlabel{section:extensions:subtasks}{{5.1.2}{63}{Subtasks}{subsection.5.1.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Task Distributions}{63}{subsection.5.1.3}\protected@file@percent }
\newlabel{section:extensions:taskweightings}{{5.1.3}{63}{Task Distributions}{subsection.5.1.3}{}}
\abx@aux@cite{Szegedy}
\abx@aux@segm{0}{0}{Szegedy}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Hyperparameter Tuning}{64}{subsection.5.1.4}\protected@file@percent }
\newlabel{section:extensions:hyperparametertuning}{{5.1.4}{64}{Hyperparameter Tuning}{subsection.5.1.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Multiple Runs}{64}{subsection.5.1.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}Methodological Extensions}{64}{section.5.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Mutual Information}{64}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Label Smoothing}{64}{subsection.5.2.2}\protected@file@percent }
\abx@aux@segm{0}{0}{Yu}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces A breakdown of the sentiment classes in the SemEval ABSA task\relax }}{65}{table.5.1}\protected@file@percent }
\newlabel{table:extensions:semevalclasses}{{5.1}{65}{A breakdown of the sentiment classes in the SemEval ABSA task\relax }{table.5.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}Meta Learning}{65}{section.5.3}\protected@file@percent }
\newlabel{section:extensions:meta}{{5.3}{65}{Meta Learning}{section.5.3}{}}
\abx@aux@segm{0}{0}{Nichol}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.4}Knowledge Graph Extensions}{66}{section.5.4}\protected@file@percent }
\abx@aux@segm{0}{0}{Sun2019a}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{67}{chapter.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {A}Streetbees: A Company Profile \& Project Relevancy}{69}{appendix.A}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix:streetbees}{{A}{69}{Streetbees: A Company Profile \& Project Relevancy}{appendix.A}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {B}Additional Findings}{71}{appendix.B}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix:additionalfindings}{{B}{71}{Additional Findings}{appendix.B}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {C}Code listings}{72}{appendix.C}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix:code}{{C}{72}{Code listings}{appendix.C}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{References}{73}{appendix.C}\protected@file@percent }
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{Collobert}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Kang2013}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Brill}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Chiticariu2013}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Kaur2014}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Nederhof}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Tenney2019a}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Nilsson}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Harris1954}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Brown}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Mikolov}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Mikolov2013}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Pennington}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{VanDerMaaten2008}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Kullback1951}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Elman1990}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Werbos}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Pascanu}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Hochreiter1997}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Varsamopoulos2018}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Graves2013}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Peters2018a}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{RadfordGPT}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Vaswani}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Dai2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{He2015}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Huang2016}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ImageNet}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{COCO}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Howard2018}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Cheng2016}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Parikh}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Paulus2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Lin2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Ba2016}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Jain}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Devlin2018}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Wang2018}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Taylor1953}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Liu2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Wu2016}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Yang2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{XLNetTeam2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Tenney2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Radford2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Socher}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Kiritchenko2014}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Sun2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Garland2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Cai2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Tjong}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{tensorboard}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Kuleshov2000}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Szegedy}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Caruana1997}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{RuderThesis}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Parisi2018}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Ruder2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Baxter1997}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Stickland2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Sanh2018}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Sun2019a}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Finn2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Nichol}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Wolf}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Chen2018}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Gu}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Yu}{none/global//global/global}
