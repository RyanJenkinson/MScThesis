Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@techreport{Socher,
abstract = {Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment composition-ality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model out-performs all previous methods on several met-rics. It pushes the state of the art in single sentence positive/negative classification from 80{\%} up to 85.4{\%}. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7{\%}, an improvement of 9.7{\%} over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.},
annote = {SST-2},
author = {Socher, Richard and Perelygin, Alex and Wu, Jean Y and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Socher et al. - Unknown - Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank.pdf:pdf},
title = {{Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank}},
url = {http://nlp.stanford.edu/}
}
@techreport{Tjong,
abstract = {We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance .},
author = {Tjong, Erik F and Sang, Kim and {De Meulder}, Fien},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Tjong, Sang, De Meulder - Unknown - Introduction to the CoNLL-2003 Shared Task Language-Independent Named Entity Recognition.pdf:pdf},
title = {{Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition}},
url = {http://lcg-www.uia.ac.be/conll2003/ner/}
}
@article{Chen2018,
abstract = {Semantic composition functions have been playing a pivotal role in neural representation learning of text sequences. In spite of their success, most existing models suffer from the underfitting problem: they use the same shared compositional function on all the positions in the sequence, thereby lacking expressive power due to incapacity to capture the richness of compositionality. Besides, the composition functions of different tasks are independent and learned from scratch. In this paper, we propose a new sharing scheme of composition function across multiple tasks. Specifically, we use a shared meta-network to capture the meta-knowledge of semantic composition and generate the parameters of the task-specific semantic composition models. We conduct extensive experiments on two types of tasks, text classification and sequence tagging, which demonstrate the benefits of our approach. Besides, we show that the shared meta-knowledge learned by our proposed model can be regarded as off-the-shelf knowledge and easily transferred to new tasks.},
author = {Chen, Junkun and Qiu, Xipeng and Liu, Pengfei and Huang, Xuanjing},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/17140-77564-1-PB.pdf:pdf},
isbn = {9781577358008},
journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
keywords = {Natural Language Processing and Machine Learning T,meta},
mendeley-tags = {meta},
pages = {5070--5077},
title = {{Meta multi-task learning for sequence modeling}},
year = {2018}
}
@article{Wang2018,
abstract = {For natural language understanding (NLU) technology to be maximally useful, both practically and as a scientific object of study, it must be general: it must be able to process language in a way that is not exclusively tailored to any one specific task or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark (GLUE), a tool for evaluating and analyzing the performance of models across a diverse range of existing NLU tasks. GLUE is model-agnostic, but it incentivizes sharing knowledge across tasks because certain tasks have very limited training data. We further provide a hand-crafted diagnostic test suite that enables detailed linguistic analysis of NLU models. We evaluate baselines based on current methods for multi-task and transfer learning and find that they do not immediately give substantial improvements over the aggregate performance of training a separate model per task, indicating room for improvement in developing general and robust NLU systems.},
archivePrefix = {arXiv},
arxivId = {1804.07461},
author = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
eprint = {1804.07461},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Wang et al. - 2018 - GLUE A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.pdf:pdf},
month = {apr},
title = {{GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding}},
url = {http://arxiv.org/abs/1804.07461},
year = {2018}
}
@techreport{COCO,
abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
archivePrefix = {arXiv},
arxivId = {1405.0312v3},
author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C Lawrence and Dol{\'{i}}, Piotr},
eprint = {1405.0312v3},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Lin et al. - Unknown - Microsoft COCO Common Objects in Context.pdf:pdf},
title = {{Microsoft COCO: Common Objects in Context}},
url = {https://arxiv.org/pdf/1405.0312.pdf}
}
@inproceedings{ImageNet,
author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and {Kai Li} and {Li Fei-Fei}},
booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2009.5206848},
isbn = {978-1-4244-3992-8},
month = {jun},
pages = {248--255},
publisher = {IEEE},
title = {{ImageNet: A large-scale hierarchical image database}},
url = {https://ieeexplore.ieee.org/document/5206848/},
year = {2009}
}
