Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@techreport{Ruder,
abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
archivePrefix = {arXiv},
arxivId = {1609.04747v2},
author = {Ruder, Sebastian},
eprint = {1609.04747v2},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Ruder - Unknown - An overview of gradient descent optimization algorithms.pdf:pdf},
title = {{An overview of gradient descent optimization algorithms *}},
url = {http://caffe.berkeleyvision.org/tutorial/solver.html}
}
@article{Huang2016,
abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet .},
archivePrefix = {arXiv},
arxivId = {1608.06993},
author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
eprint = {1608.06993},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Huang et al. - 2016 - Densely Connected Convolutional Networks.pdf:pdf},
month = {aug},
title = {{Densely Connected Convolutional Networks}},
url = {http://arxiv.org/abs/1608.06993},
year = {2016}
}
@article{Kaur2014,
author = {Kaur, Gaganpreet},
doi = {10.15623/ijret.2014.0301026},
journal = {International Journal of Research in Engineering and Technology},
month = {jan},
number = {01},
pages = {168--174},
title = {{USAGE OF REGULAR EXPRESSIONS IN NLP}},
url = {https://ijret.org/volumes/2014v03/i01/IJRET20140301026.pdf},
volume = {03},
year = {2014}
}
@techreport{Szegedy,
abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2{\%} top-1 and 5.6{\%} top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5{\%} top-5 error and 17.3{\%} top-1 error.},
annote = {Label Smoothing},
archivePrefix = {arXiv},
arxivId = {1512.00567v3},
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon},
eprint = {1512.00567v3},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Szegedy et al. - Unknown - Rethinking the Inception Architecture for Computer Vision.pdf:pdf},
isbn = {1512.00567v3},
title = {{Rethinking the Inception Architecture for Computer Vision}},
url = {https://arxiv.org/pdf/1512.00567.pdf}
}
@techreport{VanDerMaaten2008,
abstract = {We present a new technique called "t-SNE" that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualiza-tions produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
author = {{Van Der Maaten}, Laurens and Hinton, Geoffrey},
booktitle = {Journal of Machine Learning Research},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Van Der Maaten, Hinton - 2008 - Visualizing Data using t-SNE.pdf:pdf},
keywords = {dimensionality reduction,embedding algorithms,manifold learning,multidimensional scaling,visualization},
pages = {2579--2605},
title = {{Visualizing Data using t-SNE}},
url = {http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf},
volume = {9},
year = {2008}
}
@techreport{Nilsson,
annote = {For the history of AI, repopularisation of DL etc},
author = {Nilsson, Nils J},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Nilsson - Unknown - THE QUEST FOR ARTIFICIAL INTELLIGENCE A HISTORY OF IDEAS AND ACHIEVEMENTS.pdf:pdf},
isbn = {0521122937},
title = {{THE QUEST FOR ARTIFICIAL INTELLIGENCE A HISTORY OF IDEAS AND ACHIEVEMENTS}},
url = {http://www.cambridge.org/us/0521122937http://www.cambridge.org/us/0521122937http://www.cambridge.org/us/0521122937}
}
@article{He2015,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
annote = {Resnet reference},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
eprint = {1512.03385},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:pdf},
month = {dec},
title = {{Deep Residual Learning for Image Recognition}},
url = {http://arxiv.org/abs/1512.03385},
year = {2015}
}
@techreport{Cai2017,
abstract = {Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximumly preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios.},
archivePrefix = {arXiv},
arxivId = {1709.07604v3},
author = {Cai, Hongyun and Zheng, Vincent W and {Chen-Chuan Chang}, Kevin},
booktitle = {IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING},
eprint = {1709.07604v3},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Cai, Zheng, Chen-Chuan Chang - 2017 - A Comprehensive Survey of Graph Embedding Problems, Techniques and Applications.pdf:pdf},
keywords = {Index Terms-Graph embedding,graph analytics,graph embedding survey,network embedding !},
pages = {1},
title = {{A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications}},
url = {https://arxiv.org/pdf/1709.07604.pdf},
volume = {XX},
year = {2017}
}
@techreport{Nederhof,
abstract = {We compare the asymptotic time complexity of left-to-right and bidirectional parsing techniques for bilexical context-free grammars, a grammar formalism that is an abstraction of language models used in several state-of-the-art real-world parsers. We provide evidence that left-to-right parsing cannot be re-alised within acceptable time-bounds if the so called correct-prefix property is to be ensured. Our evidence is based on complexity results for the representation of regular languages.},
author = {Nederhof, Mark-Jan and Stuhlsatzenhausweg, Dfki and Germany, Saarbrficken and Satta, Giorgio},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Nederhof et al. - Unknown - Left-To-Right Parsing and Bilexical Context-Free Grammars.pdf:pdf},
title = {{Left-To-Right Parsing and Bilexical Context-Free Grammars}},
url = {https://www.aclweb.org/anthology/A00-2036}
}
@article{Ba2016,
abstract = {Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.},
archivePrefix = {arXiv},
arxivId = {1607.06450},
author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
eprint = {1607.06450},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Ba, Kiros, Hinton - 2016 - Layer Normalization.pdf:pdf},
month = {jul},
title = {{Layer Normalization}},
url = {http://arxiv.org/abs/1607.06450},
year = {2016}
}
@article{Harris1954,
author = {Harris, Zellig S},
doi = {10.1080/00437956.1954.11659520},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Harris - 1954 - Distributional Structure.pdf:pdf},
journal = {Distributional Structure, WORD},
number = {3},
pages = {146--162},
title = {{Distributional Structure}},
url = {https://www.tandfonline.com/action/journalInformation?journalCode=rwrd20},
volume = {10},
year = {1954}
}
@inproceedings{Garland2019,
author = {Garland, Ryan and Goldberg, Sophia and {Mathiesen (Streetbees)}, Erik},
booktitle = {EurNLP},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Garland, Goldberg, Mathiesen (Streetbees) - 2019 - Embedding Knowledge Graphs as Languages with BERT.pdf:pdf},
title = {{Embedding Knowledge Graphs as Languages with BERT}},
year = {2019}
}
@article{Kang2013,
author = {Kang, Ning and Singh, Bharat and Afzal, Zubair and van Mulligen, Erik M and Kors, Jan A},
doi = {10.1136/amiajnl-2012-001173},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Kang et al. - 2013 - Using rule-based natural language processing to improve disease normalization in biomedical text.pdf:pdf},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
month = {sep},
number = {5},
pages = {876--881},
publisher = {Narnia},
title = {{Using rule-based natural language processing to improve disease normalization in biomedical text}},
url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2012-001173},
volume = {20},
year = {2013}
}
@techreport{Collobert,
abstract = {We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.},
archivePrefix = {arXiv},
arxivId = {1103.0398v1},
author = {Collobert, Ronan and Weston, Jason and Bottou, L{\'{e}}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
eprint = {1103.0398v1},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Collobert et al. - Unknown - Natural Language Processing (almost) from Scratch.0398v1:0398v1},
keywords = {Natural Language Processing,Neural Networks},
title = {{Natural Language Processing (almost) from Scratch}},
url = {https://arxiv.org/pdf/1103.0398.pdf}
}
@techreport{Wu2016,
abstract = {Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference-sometimes prohibitively so in the case of very large data sets and large models. Several authors have also charged that NMT systems lack robustness, particularly when input sentences contain rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using residual connections as well as attention connections from the decoder network to the encoder. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units ("wordpieces") for both input and output. This method provides a good balance between the flexibility of "character"-delimited models and the efficiency of "word"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. To directly optimize the translation BLEU scores, we consider refining the models by using reinforcement learning, but we found that the improvement in the BLEU scores did not reflect in the human evaluation. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60{\%} compared to Google's phrase-based production system.},
annote = {wordpieces reference},
archivePrefix = {arXiv},
arxivId = {1609.08144v2},
author = {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and Klingner, Jeff and Shah, Apurva and Johnson, Melvin and Liu, Xiaobing and Kaiser, {\L}ukasz and Gouws, Stephan and Kato, Yoshikiyo and Kudo, Taku and Kazawa, Hideto and Stevens, Keith and Kurian, George and Patil, Nishant and Wang, Wei and Young, Cliff and Smith, Jason and Riesa, Jason and Rudnick, Alex and Vinyals, Oriol and Corrado, Greg and Hughes, Macduff and Dean, Jeffrey},
eprint = {1609.08144v2},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Wu et al. - Unknown - Google's Neural Machine Translation System Bridging the Gap between Human and Machine Translation.pdf:pdf},
title = {{Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation}},
url = {https://arxiv.org/pdf/1609.08144.pdf},
year = {2016}
}
@techreport{Chiticariu2013,
abstract = {The rise of "Big Data" analytics over unstruc-tured text has led to renewed interest in information extraction (IE). We surveyed the landscape of IE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia's perception that rule-based IE is devoid of research challenges. We make a case for the importance of rule-based IE to industry practitioners. We then lay out a research agenda in advancing the state-of-the-art in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.},
author = {Chiticariu, Laura and Li, Yunyao and Reiss, Frederick R},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Chiticariu, Li, Reiss - 2013 - Rule-based Information Extraction is Dead! Long Live Rule-based Information Extraction Systems!.pdf:pdf},
pages = {18--21},
title = {{Rule-based Information Extraction is Dead! Long Live Rule-based Information Extraction Systems!}},
url = {https://www.aclweb.org/anthology/D13-1079},
year = {2013}
}
@techreport{Brill,
abstract = {Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods. In this paper, we present a simple rule-based part of speech tagger which automatically acquires its rules and tags with accuracy comparable to stochastic taggers. The rule-based tagger has many advantages over these taggers, including: a vast reduction in stored information required, the perspicuity of a small set of meaningful rules, ease of finding and implementing improvements to the tagger, and better portability from one tag set, corpus genre or language to another. Perhaps the biggest contribution of this work is in demonstrating that the stochastic method is not the only viable method for part of speech tagging. The fact that a simple rule-based tagger that automatically learns its rules can perform so well should offer encouragement for researchers to further explore rule-based tagging, searching for a better and more expressive set of rule templates and other variations on the simple but effective theme described below.},
author = {Brill, Eric},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Brill - Unknown - A SIMPLE RULE-BASED PART OF SPEECH TAGGER.pdf:pdf},
title = {{A SIMPLE RULE-BASED PART OF SPEECH TAGGER}},
url = {https://apps.dtic.mil/dtic/tr/fulltext/u2/a460532.pdf}
}
@article{Tenney2019a,
abstract = {Contextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.},
annote = {Reference for NLP pipeline},
archivePrefix = {arXiv},
arxivId = {1905.06316},
author = {Tenney, Ian and Xia, Patrick and Chen, Berlin and Wang, Alex and Poliak, Adam and McCoy, R Thomas and Kim, Najoung and {Van Durme}, Benjamin and Bowman, Samuel R. and Das, Dipanjan and Pavlick, Ellie},
eprint = {1905.06316},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Tenney et al. - 2019 - What do you learn from context Probing for sentence structure in contextualized word representations.pdf:pdf},
month = {may},
title = {{What do you learn from context? Probing for sentence structure in contextualized word representations}},
url = {http://arxiv.org/abs/1905.06316},
year = {2019}
}
@article{Kullback1951,
author = {Kullback, S. and Leibler, R. A.},
doi = {10.1214/aoms/1177729694},
issn = {0003-4851},
journal = {The Annals of Mathematical Statistics},
month = {mar},
number = {1},
pages = {79--86},
publisher = {Institute of Mathematical Statistics},
title = {{On Information and Sufficiency}},
url = {http://projecteuclid.org/euclid.aoms/1177729694},
volume = {22},
year = {1951}
}
@techreport{Kuleshov2000,
abstract = {The stochastic multi-armed bandit problem is an important model for studying the exploration-exploitation tradeoff in reinforcement learning. Although many algorithms for the problem are well-understood theoretically, empirical confirmation of their effectiveness is generally scarce. This paper presents a thorough empirical study of the most popular multi-armed bandit algorithms. Three important observations can be made from our results. Firstly, simple heuristics such as-greedy and Boltzmann exploration outperform theoretically sound algorithms on most settings by a significant margin. Secondly, the performance of most algorithms varies dramatically with the parameters of the bandit problem. Our study identifies for each algorithm the settings where it performs well, and the settings where it performs poorly. These properties are not described by current theory, even though they can be exploited in practice in the design of heuristics. Thirdly, the algorithms' performance relative each to other is affected only by the number of bandit arms and the variance of the rewards. This finding may guide the design of subsequent empirical evaluations. In the second part of the paper, we turn our attention to an important area of application of bandit algorithms: clinical trials. Although the design of clinical trials has been one of the principal practical problems motivating research on multi-armed bandits, bandit algorithms have never been evaluated as potential treatment allocation strategies. Using data from a real study, we simulate the outcome that a 2001-2002 clinical trial would have had if bandit algorithms had been used to allocate patients to treatments. We find that an adaptive trial would have successfully treated at least 50{\%} more patients, while significantly reducing the number of adverse effects and increasing patient retention. At the end of the trial, the best treatment could have still been identified with a high level of statistical confidence. Our findings demonstrate that bandit algorithms are attractive alternatives to current adaptive treatment allocation strategies.},
archivePrefix = {arXiv},
arxivId = {1402.6028v1},
author = {Kuleshov, Volodymyr and Precup, Doina},
booktitle = {Journal of Machine Learning Research},
eprint = {1402.6028v1},
file = {:Users/ryanjenkinson/Documents/MSc Project/LaTeX Project/papers/Kuleshov, Precup - 2000 - Algorithms for the multi-armed bandit problem.pdf:pdf},
pages = {1--48},
title = {{Algorithms for the multi-armed bandit problem}},
url = {https://arxiv.org/pdf/1402.6028.pdf},
volume = {1},
year = {2000}
}
@misc{tensorboard,
author = {Google and Lanpa},
title = {{Tensorboard {\&} TensorboardX}},
url = {https://github.com/lanpa/tensorboardX},
year = {2019}
}
