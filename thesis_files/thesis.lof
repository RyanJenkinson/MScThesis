\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.1}{\ignorespaces Potential NLP ``pre-task" pipeline required for a model to solve more complex tasks\relax }}{8}{figure.1.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.2}{\ignorespaces Example ABSA Knowledge Graph Construction. \newline Here, \textbf {[LOG]} = ``The restaurant was really cheap, but it didnt have a great vibe". \newline An alternative presentation of the above is that the aspect nodes have sentiment attributes, rather than an additional relation to a seperate node in the graph.\relax }}{9}{figure.1.2}% 
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.1}{\ignorespaces Continuous Bag Of Word (CBOW) models vs Skip Gram Models \newline Skip Gram models predict a words context given the word itself, whereas CBOW models predict a word given its context.\relax }}{15}{figure.2.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.2}{\ignorespaces The reduced dimensionality word embedding space found using \texttt {word2vec} \cite {Mikolov} and the algebraic relationship between clusters of words in this space\relax }}{16}{figure.2.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.3}{\ignorespaces One LSTM cell with corresponding equations, image taken from \cite {Varsamopoulos2018}. There is one cell for each word in the input sentence. We input embedding $x_t$, and propagate forward the hidden state $h_t$ and the cell state $C_t$. $\{i_t, f_t, o_t\}$ are the \{input, forget, output\} gates, $W^{\{i,f,o\}}$ and $U^{\{i,f,o\}}$ are learnable weight matrices.\relax }}{17}{figure.2.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Bidirectional LSTM architecture as defined in \cite {Graves2013}\relax }}{18}{figure.2.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.5}{\ignorespaces The Architecture of the Transformer Model \cite {Vaswani}\relax }}{21}{figure.2.5}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.6}{\ignorespaces BERT vs OpenAI GPT vs ELMo\relax }}{22}{figure.2.6}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.7}{\ignorespaces BERT Token Prediction\relax }}{24}{figure.2.7}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.8}{\ignorespaces BERT Embeddings. In addition to the learned token embeddings, there are segment embeddings (as to whether or not we are in the first sentence or second sentence) and positional embeddings \cite {Vaswani} that help indicate the relative positioning of tokens in the sentence.\relax }}{25}{figure.2.8}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.9}{\ignorespaces BERT correcting its predictions along the model depth layers, taken from \cite {Tenney2019}\relax }}{26}{figure.2.9}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.10}{\ignorespaces Transfer Learning Illustration\relax }}{34}{figure.2.10}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.11}{\ignorespaces Hard Parameter Sharing, with image taken from \cite {Ruder2017}\relax }}{35}{figure.2.11}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.12}{\ignorespaces Soft Parameter Sharing, with image taken from \cite {Ruder2017}\relax }}{35}{figure.2.12}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.13}{\ignorespaces ERNIE 2.0 Methodology \cite {Sun2019a}\relax }}{37}{figure.2.13}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.14}{\ignorespaces ERNIE 2.0 Pretraining Task Framework \cite {Sun2019a}\relax }}{38}{figure.2.14}% 
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.1}{\ignorespaces Countplot of the Streetbees Data (emotion) categories\relax }}{45}{figure.3.1}% 
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.1}{\ignorespaces SemEval \{2,3,4\}-way accuracies on BERT and XLNet for our sampling modes\relax }}{51}{figure.caption.35}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.2}{\ignorespaces SemEval \{2,3,4\}-way accuracies relative to SOTA performance on BERT and XLNet for our sampling modes\relax }}{52}{figure.caption.36}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.3}{\ignorespaces SemEval Precision, Recall and $F_1$ Scores on BERT and XLNet for our sampling modes\relax }}{53}{figure.caption.37}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.4}{\ignorespaces SST-2 vs IMDB in the single task and multitask learning setting\relax }}{59}{figure.4.4}% 
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
